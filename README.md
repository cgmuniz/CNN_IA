# ü§ñ EP2 - Redes Neurais CNN e MLP com HOG para Classifica√ß√£o de D√≠gitos (MNIST)

**Disciplina:** ACH2016 - Intelig√™ncia Artificial (2025)  
**Projeto:** Exerc√≠cio-Programa 2

**Autores:**
*   11796718 ‚Äì LUCAS SARTOR CHAUVIN
*   12873188 ‚Äì GABRIEL BERNARDINI SCHIMIDT
*   14564405 ‚Äì CAU√É GABRIEL MUNIZ DOS SANTOS
*   14592498 ‚Äì LUIS YUDI ODAKE FERREIRA
*   14778136 ‚Äì LEONEL MARCO ANTONIO MORGADO

---

## üìú Vis√£o Geral do Projeto

Este projeto implementa e compara duas abordagens distintas para o problema de classifica√ß√£o de d√≠gitos do dataset MNIST:

1.  **Rede Neural Convolucional (CNN):** Um modelo de deep learning que aprende a extrair caracter√≠sticas automaticamente a partir dos pixels brutos da imagem.
2.  **Multi-Layer Perceptron (MLP) com HOG:** Uma abordagem mais tradicional onde as caracter√≠sticas s√£o extra√≠das manualmente usando o descritor HOG (Histogram of Oriented Gradients) e, em seguida, utilizadas para treinar uma rede neural densa (MLP).

O c√≥digo executa quatro experimentos distintos para uma an√°lise completa:
*   CNN em tarefa bin√°ria (d√≠gitos 0 vs. 1)
*   CNN em tarefa multiclasse (d√≠gitos 0 a 9)
*   MLP + HOG em tarefa bin√°ria
*   MLP + HOG em tarefa multiclasse

Para cada experimento, o projeto utiliza o **Keras Tuner** para otimizar os hiperpar√¢metros do modelo, garantindo uma compara√ß√£o justa e robusta entre as arquiteturas.

## ‚ú® Principais Caracter√≠sticas

*   **Otimiza√ß√£o de Hiperpar√¢metros:** Utiliza `keras_tuner` com Otimiza√ß√£o Bayesiana para encontrar as melhores arquiteturas de modelo.
*   **Compara√ß√£o de Abordagens:** Avalia de forma sistem√°tica o desempenho da extra√ß√£o de caracter√≠sticas aprendida (CNN) vs. manual (HOG).
*   **Gera√ß√£o Autom√°tica de Artefatos:** Salva automaticamente os resultados, m√©tricas, gr√°ficos e pesos de cada modelo para an√°lise posterior.
*   **Visualiza√ß√£o Comparativa:** Gera uma tabela e um gr√°fico de barras ao final da execu√ß√£o, comparando a acur√°cia de todos os experimentos.

## üöÄ Como Executar

Para executar o projeto, siga os passos abaixo.

### 1. Pr√©-requisitos

*   Python 3.9 ou superior

### 2. Instala√ß√£o

**a. Crie e ative um ambiente virtual (altamente recomendado):**
```bash
# Comando para criar o ambiente virtual
python -m venv venv

# Ativar no Windows
.\venv\Scripts\activate

# Ativar no macOS/Linux
source venv/bin/activate
```

**b. Instale as depend√™ncias:**
O arquivo `requirements.txt` cont√©m todas as bibliotecas necess√°rias. Instale-as com um √∫nico comando:
```bash
pip install -r requirements.txt
```

### 3. Execu√ß√£o do Script Principal

Execute o arquivo `main.py`. O script ir√° rodar todos os quatro experimentos em sequ√™ncia.

```bash
python main.py
```
**Aten√ß√£o:** A execu√ß√£o pode demorar um pouco, pois envolve otimiza√ß√£o e treinamento de quatro modelos neurais. Ao final, os resultados e gr√°ficos ser√£o gerados.

## üìä Artefatos Gerados

Ap√≥s a execu√ß√£o, os seguintes artefatos ser√£o criados na pasta do projeto:

**1. Estrutura de Pastas `runs/`:**
Uma pasta `runs` ser√° criada, contendo subdiret√≥rios para cada um dos quatro experimentos:

```
runs/
‚îú‚îÄ‚îÄ cnn_binary/
‚îú‚îÄ‚îÄ cnn_multiclass/
‚îú‚îÄ‚îÄ mlp_hog_binary/
‚îî‚îÄ‚îÄ mlp_hog_multiclass/
```

**2. Conte√∫do de cada pasta de experimento:**
Dentro de cada subdiret√≥rio (ex: `runs/cnn_multiclass/`), voc√™ encontrar√°:

*   `results.json`: Um arquivo JSON com os melhores hiperpar√¢metros encontrados e as m√©tricas finais de avalia√ß√£o (loss e acur√°cia).
*   `confusion_matrix.png`: Gr√°fico da matriz de confus√£o do modelo no conjunto de teste.
*   `learning_curve.png`: Gr√°fico da curva de aprendizado (Loss vs. √âpocas).
*   `accuracy_curve.png`: Gr√°fico da curva de acur√°cia (Acur√°cia vs. √âpocas).
*   `history.pkl`: Arquivo Pickle com o hist√≥rico completo de treinamento.
*   `initial_weights.pkl` / `final_weights.pkl`: Pesos do modelo antes e depois do treinamento.
*   `predictions.pkl`: Predi√ß√µes do modelo no conjunto de teste.
*   `tuning_trials/`: Pasta gerada pelo Keras Tuner com os detalhes de cada tentativa de otimiza√ß√£o.

**3. Gr√°fico Comparativo Final:**
Na raiz do projeto, um arquivo de imagem ser√° gerado:

*   `comparison_accuracy.png`: Um gr√°fico de barras comparando a acur√°cia final de todos os quatro experimentos, facilitando a an√°lise dos resultados.